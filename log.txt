nohup: ignoring input
Importing module 'gym_37' (/home/achard/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_37.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/achard/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
PyTorch version 1.8.1
Device count 2
/home/achard/isaacgym/python/isaacgym/_bindings/src/gymtorch
Using /home/achard/.cache/torch_extensions as PyTorch extensions root...
Emitting ninja build file /home/achard/.cache/torch_extensions/gymtorch/build.ninja...
Building extension module gymtorch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module gymtorch...
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
num_dof:  18
Creating 300 environments.
Setting initial dof position
Joint count: 27600
velocity 2200.0
effort 10000000000.0
stiffness 2200.0
damping 50.0
mini_chunk_size:  136
rollout_size:  2176
Action asked to go over !!!
tensor([[-0.1955, -0.1809, -0.8303,  ...,  0.4747,  0.3160, -0.0112],
        [ 0.4817,  0.4075,  0.3411,  ..., -0.0232, -0.2464, -0.0748],
        [-0.1904, -0.3013, -0.2285,  ...,  0.0098,  0.0632,  0.1529],
        ...,
        [ 0.3125,  0.2536, -0.0606,  ...,  0.0450, -0.2681,  0.0495],
        [-0.0790, -0.1425, -0.5721,  ..., -0.2500,  0.0231, -0.1164],
        [ 0.9654, -0.3027, -0.1381,  ...,  0.6613,  0.1318,  0.0100]],
       device='cuda:0')
tensor([False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False,  True, False], device='cuda:0')
Steps: 0000 | Opt Step: 0000 | Reward 0.0049 | Action Var 0.1000
Steps: 0100 | Opt Step: 0000 | Reward 0.2441 | Action Var 0.0980
Steps: 0200 | Opt Step: 0000 | Reward 0.2327 | Action Var 0.0960
Steps: 0300 | Opt Step: 0000 | Reward 0.2119 | Action Var 0.0940
Steps: 0400 | Opt Step: 0000 | Reward 0.2520 | Action Var 0.0920
Steps: 0500 | Opt Step: 0000 | Reward 0.2111 | Action Var 0.0900
Steps: 0600 | Opt Step: 0000 | Reward 0.2416 | Action Var 0.0880
Steps: 0700 | Opt Step: 0000 | Reward 0.2325 | Action Var 0.0860
Steps: 0800 | Opt Step: 0000 | Reward 0.2268 | Action Var 0.0840
Steps: 0900 | Opt Step: 0000 | Reward 0.2486 | Action Var 0.0820
Steps: 1000 | Opt Step: 0000 | Reward 0.2262 | Action Var 0.0800
Steps: 1100 | Opt Step: 0000 | Reward 0.2506 | Action Var 0.0780
Steps: 1200 | Opt Step: 0000 | Reward 0.2447 | Action Var 0.0760
Steps: 1300 | Opt Step: 0000 | Reward 0.2422 | Action Var 0.0740
Steps: 1400 | Opt Step: 0000 | Reward 0.2605 | Action Var 0.0720
Steps: 1500 | Opt Step: 0000 | Reward 0.2429 | Action Var 0.0700
Steps: 1600 | Opt Step: 0000 | Reward 0.2596 | Action Var 0.0680
Steps: 1700 | Opt Step: 0000 | Reward 0.2527 | Action Var 0.0660
Steps: 1800 | Opt Step: 0000 | Reward 0.2496 | Action Var 0.0640
Steps: 1900 | Opt Step: 0000 | Reward 0.2686 | Action Var 0.0620
Steps: 2000 | Opt Step: 0000 | Reward 0.2573 | Action Var 0.0600
Steps: 2100 | Opt Step: 0000 | Reward 0.2626 | Action Var 0.0580
Training
Steps: 2200 | Opt Step: 0075 | Reward 0.2737 | Action Var 0.0560
Steps: 2300 | Opt Step: 0075 | Reward 0.3180 | Action Var 0.0540
Steps: 2400 | Opt Step: 0075 | Reward 0.3314 | Action Var 0.0520
Steps: 2500 | Opt Step: 0075 | Reward 0.3229 | Action Var 0.0500
Steps: 2600 | Opt Step: 0075 | Reward 0.3223 | Action Var 0.0480
Steps: 2700 | Opt Step: 0075 | Reward 0.3378 | Action Var 0.0460
Steps: 2800 | Opt Step: 0075 | Reward 0.3283 | Action Var 0.0440
Steps: 2900 | Opt Step: 0075 | Reward 0.3357 | Action Var 0.0420
Steps: 3000 | Opt Step: 0075 | Reward 0.3382 | Action Var 0.0400
Steps: 3100 | Opt Step: 0075 | Reward 0.3274 | Action Var 0.0380
Steps: 3200 | Opt Step: 0075 | Reward 0.3415 | Action Var 0.0360
Steps: 3300 | Opt Step: 0075 | Reward 0.3414 | Action Var 0.0340
Steps: 3400 | Opt Step: 0075 | Reward 0.3385 | Action Var 0.0320
Steps: 3500 | Opt Step: 0075 | Reward 0.3464 | Action Var 0.0300
Steps: 3600 | Opt Step: 0075 | Reward 0.3410 | Action Var 0.0280
Steps: 3700 | Opt Step: 0075 | Reward 0.3442 | Action Var 0.0260
Steps: 3800 | Opt Step: 0075 | Reward 0.3517 | Action Var 0.0240
Steps: 3900 | Opt Step: 0075 | Reward 0.3464 | Action Var 0.0220
Steps: 4000 | Opt Step: 0075 | Reward 0.3451 | Action Var 0.0200
Steps: 4100 | Opt Step: 0075 | Reward 0.3554 | Action Var 0.0180
Steps: 4200 | Opt Step: 0075 | Reward 0.3472 | Action Var 0.0160
Steps: 4300 | Opt Step: 0075 | Reward 0.3510 | Action Var 0.0140
Training
Steps: 4400 | Opt Step: 0150 | Reward 0.3357 | Action Var 0.0120
Steps: 4500 | Opt Step: 0150 | Reward 0.3356 | Action Var 0.0100
Steps: 4600 | Opt Step: 0150 | Reward 0.3328 | Action Var 0.0100
Steps: 4700 | Opt Step: 0150 | Reward 0.3353 | Action Var 0.0100
Steps: 4800 | Opt Step: 0150 | Reward 0.3377 | Action Var 0.0100
Steps: 4900 | Opt Step: 0150 | Reward 0.3388 | Action Var 0.0100
Steps: 5000 | Opt Step: 0150 | Reward 0.3336 | Action Var 0.0100
Steps: 5100 | Opt Step: 0150 | Reward 0.3340 | Action Var 0.0100
Steps: 5200 | Opt Step: 0150 | Reward 0.3390 | Action Var 0.0100
Steps: 5300 | Opt Step: 0150 | Reward 0.3389 | Action Var 0.0100
Steps: 5400 | Opt Step: 0150 | Reward 0.3344 | Action Var 0.0100
dof_at_limit_cost tensor([0.3000, 0.1000, 0.1000, 0.2000, 0.3000, 0.1000, 0.0000, 0.2000, 0.4000,
        0.1000, 0.2000, 0.2000, 0.2000, 0.1000, 0.1000, 0.3000, 0.2000, 0.0000,
        0.1000, 0.2000, 0.1000, 0.1000, 0.2000, 0.3000, 0.2000, 0.2000, 0.2000,
        0.0000, 0.1000, 0.1000, 0.2000, 0.0000, 0.1000, 0.1000, 0.1000, 0.0000,
        0.1000, 0.1000, 0.1000, 0.2000, 0.2000, 0.1000, 0.1000, 0.3000, 0.2000,
        0.1000, 0.3000, 0.2000, 0.2000, 0.2000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.3000, 0.2000, 0.2000, 0.1000, 0.2000, 0.1000, 0.2000, 0.1000, 0.1000,
        0.0000, 0.3000, 0.0000, 0.1000, 0.2000, 0.0000, 0.1000, 0.1000, 0.2000,
        0.1000, 0.0000, 0.2000, 0.1000, 0.2000, 0.1000, 0.2000, 0.1000, 0.2000,
        0.0000, 0.0000, 0.1000, 0.2000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.2000, 0.0000, 0.0000, 0.3000,
        0.2000, 0.1000, 0.3000, 0.1000, 0.1000, 0.1000, 0.0000, 0.2000, 0.1000,
        0.2000, 0.1000, 0.1000, 0.2000, 0.2000, 0.1000, 0.1000, 0.0000, 0.1000,
        0.2000, 0.0000, 0.2000, 0.3000, 0.2000, 0.1000, 0.1000, 0.0000, 0.1000,
        0.1000, 0.0000, 0.0000, 0.2000, 0.1000, 0.1000, 0.1000, 0.2000, 0.0000,
        0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.3000, 0.2000, 0.0000,
        0.2000, 0.0000, 0.2000, 0.3000, 0.1000, 0.0000, 0.4000, 0.2000, 0.3000,
        0.1000, 0.2000, 0.3000, 0.0000, 0.2000, 0.2000, 0.2000, 0.1000, 0.2000,
        0.1000, 0.3000, 0.2000, 0.2000, 0.0000, 0.1000, 0.3000, 0.2000, 0.3000,
        0.1000, 0.2000, 0.4000, 0.1000, 0.1000, 0.1000, 0.2000, 0.1000, 0.0000,
        0.2000, 0.1000, 0.2000, 0.2000, 0.2000, 0.0000, 0.1000, 0.2000, 0.1000,
        0.3000, 0.3000, 0.1000, 0.2000, 0.3000, 0.2000, 0.1000, 0.3000, 0.0000,
        0.1000, 0.3000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.1000,
        0.1000, 0.2000, 0.0000, 0.1000, 0.1000, 0.1000, 0.2000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.3000, 0.1000, 0.1000,
        0.0000, 0.3000, 0.1000, 0.0000, 0.1000, 0.2000, 0.2000, 0.1000, 0.1000,
        0.3000, 0.4000, 0.1000, 0.2000, 0.2000, 0.2000, 0.1000, 0.2000, 0.1000,
        0.2000, 0.1000, 0.2000, 0.1000, 0.1000, 0.3000, 0.2000, 0.1000, 0.1000,
        0.1000, 0.2000, 0.1000, 0.1000, 0.2000, 0.2000, 0.1000, 0.1000, 0.2000,
        0.0000, 0.0000, 0.3000, 0.3000, 0.3000, 0.2000, 0.1000, 0.0000, 0.0000,
        0.1000, 0.1000, 0.2000, 0.2000, 0.0000, 0.1000, 0.0000, 0.0000, 0.2000,
        0.0000, 0.0000, 0.1000, 0.2000, 0.1000, 0.2000, 0.0000, 0.0000, 0.2000,
        0.2000, 0.0000, 0.1000, 0.1000, 0.4000, 0.1000, 0.2000, 0.3000, 0.2000,
        0.0000, 0.1000, 0.4000], device='cuda:0')
tensor([[0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0],
        [0, 0, 0, 1, 0, 0],
        ...,
        [0, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 0]], device='cuda:0')
tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000,
        0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000,
        0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.2000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000,
        0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000,
        0.0000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.0000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.0000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.2000, 0.1000,
        0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000,
        0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000,
        0.1000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000,
        0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.2000,
        0.1000, 0.1000, 0.0000, 0.1000, 0.0000, 0.0000, 0.1000, 0.1000, 0.1000,
        0.0000, 0.1000, 0.0000], device='cuda:0')
Steps: 5500 | Opt Step: 0150 | Reward 0.3331 | Action Var 0.0100
Steps: 5600 | Opt Step: 0150 | Reward 0.3377 | Action Var 0.0100
Steps: 5700 | Opt Step: 0150 | Reward 0.3366 | Action Var 0.0100
Steps: 5800 | Opt Step: 0150 | Reward 0.3353 | Action Var 0.0100
Steps: 5900 | Opt Step: 0150 | Reward 0.3327 | Action Var 0.0100
Steps: 6000 | Opt Step: 0150 | Reward 0.3376 | Action Var 0.0100
Steps: 6100 | Opt Step: 0150 | Reward 0.3375 | Action Var 0.0100
Steps: 6200 | Opt Step: 0150 | Reward 0.3366 | Action Var 0.0100
Steps: 6300 | Opt Step: 0150 | Reward 0.3326 | Action Var 0.0100
Steps: 6400 | Opt Step: 0150 | Reward 0.3368 | Action Var 0.0100
Steps: 6500 | Opt Step: 0150 | Reward 0.3370 | Action Var 0.0100
Training
Steps: 6600 | Opt Step: 0225 | Reward 0.1936 | Action Var 0.0100
Steps: 6700 | Opt Step: 0225 | Reward 0.1396 | Action Var 0.0100
Steps: 6800 | Opt Step: 0225 | Reward 0.1388 | Action Var 0.0100
Steps: 6900 | Opt Step: 0225 | Reward 0.1372 | Action Var 0.0100
Steps: 7000 | Opt Step: 0225 | Reward 0.1372 | Action Var 0.0100
Steps: 7100 | Opt Step: 0225 | Reward 0.1391 | Action Var 0.0100
Steps: 7200 | Opt Step: 0225 | Reward 0.1387 | Action Var 0.0100
Steps: 7300 | Opt Step: 0225 | Reward 0.1370 | Action Var 0.0100
Steps: 7400 | Opt Step: 0225 | Reward 0.1381 | Action Var 0.0100
Steps: 7500 | Opt Step: 0225 | Reward 0.1376 | Action Var 0.0100
Steps: 7600 | Opt Step: 0225 | Reward 0.1367 | Action Var 0.0100
Steps: 7700 | Opt Step: 0225 | Reward 0.1398 | Action Var 0.0100
Steps: 7800 | Opt Step: 0225 | Reward 0.1374 | Action Var 0.0100
Steps: 7900 | Opt Step: 0225 | Reward 0.1373 | Action Var 0.0100
Steps: 8000 | Opt Step: 0225 | Reward 0.1389 | Action Var 0.0100
Steps: 8100 | Opt Step: 0225 | Reward 0.1398 | Action Var 0.0100
Steps: 8200 | Opt Step: 0225 | Reward 0.1396 | Action Var 0.0100
Steps: 8300 | Opt Step: 0225 | Reward 0.1383 | Action Var 0.0100
Steps: 8400 | Opt Step: 0225 | Reward 0.1370 | Action Var 0.0100
Steps: 8500 | Opt Step: 0225 | Reward 0.1368 | Action Var 0.0100
Steps: 8600 | Opt Step: 0225 | Reward 0.1397 | Action Var 0.0100
Steps: 8700 | Opt Step: 0225 | Reward 0.1368 | Action Var 0.0100
Training
saving...
saved!
Steps: 8800 | Opt Step: 0300 | Reward -0.0830 | Action Var 0.0100
Steps: 8900 | Opt Step: 0300 | Reward -0.1175 | Action Var 0.0100
Steps: 9000 | Opt Step: 0300 | Reward -0.1149 | Action Var 0.0100
Steps: 9100 | Opt Step: 0300 | Reward -0.1007 | Action Var 0.0100
Steps: 9200 | Opt Step: 0300 | Reward -0.1208 | Action Var 0.0100
Steps: 9300 | Opt Step: 0300 | Reward -0.1096 | Action Var 0.0100
Steps: 9400 | Opt Step: 0300 | Reward -0.1028 | Action Var 0.0100
Steps: 9500 | Opt Step: 0300 | Reward -0.1204 | Action Var 0.0100
Steps: 9600 | Opt Step: 0300 | Reward -0.1049 | Action Var 0.0100
Steps: 9700 | Opt Step: 0300 | Reward -0.1093 | Action Var 0.0100
Steps: 9800 | Opt Step: 0300 | Reward -0.1203 | Action Var 0.0100
Steps: 9900 | Opt Step: 0300 | Reward -0.1033 | Action Var 0.0100
Steps: 10000 | Opt Step: 0300 | Reward -0.1141 | Action Var 0.0100
Steps: 10100 | Opt Step: 0300 | Reward -0.1172 | Action Var 0.0100
Steps: 10200 | Opt Step: 0300 | Reward -0.1012 | Action Var 0.0100
